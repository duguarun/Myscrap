import sys,requests,json,os
from datetime import datetime
from bs4 import BeautifulSoup
start=datetime.now()
print(start)


def scraping():
    for i in url:
        page = requests.get(i)
        soup = BeautifulSoup(page.content, 'html.parser')
        filtered = soup.find("ul", {"id": "product_list"})
        content= [ Deacthlon(i).to_dict() for i in filtered ]
        return content


class Deacthlon:
    def __init__(self,html_content ):
        self.price = html_content.find("div", {"class": "sticker-price sticker-price--normal"}).get_text().replace('â‚¹ ','')
        self.manufac = html_content.find("span", {"class": "manufacturer"}).get_text()
        self.model = html_content.find("a", {"class": "product-name"}).get_text()
    def to_dict(self):
        return  self.__dict__

def pagination():
    global url
    url=["https://www.decathlon.in/15107-bikes"]
    page = requests.get("https://www.decathlon.in/15107-bikes")
    soup = BeautifulSoup(page.content, 'html.parser')
    pages=soup.find("div", {"id":"pagination_bottom"})
    for i in pages.find_all('a'):
        url.append("https://www.decathlon.in/15107-bikes"+ i.get('href'))
    scrape_contents = [ scraping() for i in (list(set(url))) ]
    return  scrape_contents
print(json.dumps((pagination())))

end=datetime.now()
print(end)

